CoDA 2016 + BIDS
----------------

Introduction
- Motivation (broad)
  - I am concerned about
    - global climate and environmental goals
    - global and domestic security goals
    - economic prosperity
  - We can (at least partially) address these issues through nuclear innovation:
    - advanced reactor design, sustain current reactors
    - nuclear security applications: monitoring, nonproliferation, detection,
      etc.
- Motivation (my role)
  - To facilitate innovation across all of these areas, we need predictive
    simulation: better designs; limit slow, costly experiments
  - I build tools that people use to design and analyze these systems
  - with a focus on tools that work on very large machines

- Outline talk
 
Background
- What is the transport equation?
  - to design a nuclear system, we need to know where all the neutrons are
  - the transport equation (this awesome thing) tells us that
- This problem is hard
  - the problems we want to solve are really big: 6D, complex data, physically
    challenging problems
  - We also might want coupled multiphysics
  - We can do this deterministically or with Monte Carlo; each present pretty big
    challenges
- Where are we now?
  - Many existing tools are tuned to predict what we already know, not new
    things: 
    - need increased accuracy and resolution, coupled multiphysics, and
      confidence in solvers
    - To accomplish this, we really need to be able use huge machines. We are
      just starting to be able to take advantage of heterogenous architecture;
      can we make it to exascale?
  - We need better nuclear data (the input that describes all of the physics):
    as we improve what we can calculate, errors in the underlying data become
    increasingly problematic 
  - We are having trouble doing analysis now, and this will get worse. We need
    innovative methods so that we can use the answers we make in some
    reasonable amount of time.


Algorithms for advanced architectures
  - To do predictive simulation we need a lot of computing power. 
     - Cutting edge hardware; describe the kinds of machines; discuss some
       challenges about using these machines.
     - We've got a lot of old codes that can't use new machines effectively, and
       as the machines become larger and more complex this becomes increasingly
       true.
  - Work I've done to capitalize on new machines across solution strategies.
    - traditional CPUs: Block Krylov + RQI + MGE
    - heterogeneous architectures: WARP
    - hybrid methods: now possible because of larger memory

- Data
  - issues that we're seeing 
    - can't make good cross sections; 
    - can't get the answer right
  - both data processing and underlying data
  - project to directly measure data and identify where processing isn't working (NIF)

- Data processing
  - challenge: things take too long to transfer, render, and process
  - I've just started thinking about this, but as we've gotten bigger machines
    we've just asked them to dump more stuff.  
    - It takes longer to go through output, render things, etc.
    - What if we worked smarter? Lower volume?
  - can we develop algorithms to interleave calculations and analysis? 
    - smarter management of data. 
    - extra calculations inside of the calculations
    - parts of the calculation might take longer, but you may have less data to
      deal with at the end so it might be more time efficient overall...

- Wrap up: the ideas I've talked about aren't unique to nuclear engineering;
  it's likely you're all facing challenges that are like at least some of
  these. I've talked about what I'm doing to face some of them, hopefully we can 
  build new ideas together...




